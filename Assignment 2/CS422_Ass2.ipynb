{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d429bc5d-62f8-4a19-8ef1-d607f55dafe5",
   "metadata": {},
   "source": [
    "# Practicum Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4777cb28-d68f-42d6-908d-92ec62a1be25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Problem 1\n",
    "# Step 1: Load Online Retail Dataset for France\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the Online Retail dataset\n",
    "df = pd.read_excel(\"Online Retail.xlsx\")                              # UCI ML Repo dataset\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257ca339-948e-42f0-ba84-71e9e811566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Filter transactions for France and preprocess data for Apriori\n",
    "\n",
    "# Filter the dataset to include only transactions from France\n",
    "france_data = df[df['Country'] == 'France'].copy()\n",
    "\n",
    "# Drop rows with missing invoice or description\n",
    "france_data.dropna(subset=['InvoiceNo', 'Description'], inplace=True)\n",
    "\n",
    "# Remove cancelled transactions (InvoiceNo starting with 'C')\n",
    "france_data = france_data[~france_data['InvoiceNo'].astype(str).str.contains('C')]\n",
    "\n",
    "# Clean string columns\n",
    "france_data['InvoiceNo'] = france_data['InvoiceNo'].astype(str)\n",
    "france_data['Description'] = france_data['Description'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14454552-e39d-4b57-aa45-1bc119fba6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create basket (transaction x item) matrix\n",
    "basket = (france_data\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum()\n",
    "          .unstack(fill_value=0))\n",
    "\n",
    "# Convert quantities > 0 to 1, else 0 (binary encoding)\n",
    "basket_sets = basket.gt(0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3b40794-e743-46b6-a155-93ceebd888bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Itemset with the largest support:\n",
      "Itemset: {POSTAGE}\n",
      "Support: 0.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Generate frequent itemsets with minimum support of 5% \n",
    "# Note: apriori uses sparse matrix internally for memory efficiency\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Sort frequent itemsets by support descending\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Identify itemset with the largest support\n",
    "max_support_itemset = frequent_itemsets.iloc[0]\n",
    "print(\"\\nItemset with the largest support:\")\n",
    "print(f\"Itemset: {{{', '.join(max_support_itemset['itemsets'])}}}\")\n",
    "print(f\"Support: {max_support_itemset['support']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43412ddc-b33e-4f1d-8744-b646ecac3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule with highest confidence:\n",
      "Antecedents: JUMBO BAG WOODLAND ANIMALS\n",
      "Consequents: POSTAGE\n",
      "Support: 0.0765\n",
      "Confidence: 1.0000\n",
      "Lift: 1.3067\n",
      "\n",
      "Rule with highest lift:\n",
      "Antecedents: PACK OF 6 SKULL PAPER CUPS\n",
      "Consequents: PACK OF 6 SKULL PAPER PLATES\n",
      "Support: 0.0510\n",
      "Confidence: 0.8000\n",
      "Lift: 14.2545\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate association rules and find highest confidence and lift rules \n",
    "# Using min_threshold=0.01 to allow even low-confidence rules to be considered,\n",
    "# which ensures we don't miss interesting rules that may have low confidence but high lift.\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.01)\n",
    "\n",
    "# Rule with highest confidence\n",
    "max_confidence_rule = rules.loc[rules['confidence'].idxmax()]\n",
    "print(\"\\nRule with highest confidence:\")\n",
    "print(f\"Antecedents: {', '.join(max_confidence_rule['antecedents'])}\")\n",
    "print(f\"Consequents: {', '.join(max_confidence_rule['consequents'])}\")\n",
    "print(f\"Support: {max_confidence_rule['support']:.4f}\")\n",
    "print(f\"Confidence: {max_confidence_rule['confidence']:.4f}\")\n",
    "print(f\"Lift: {max_confidence_rule['lift']:.4f}\")\n",
    "\n",
    "# Rule with highest lift\n",
    "max_lift_rule = rules.loc[rules['lift'].idxmax()]\n",
    "print(\"\\nRule with highest lift:\")\n",
    "print(f\"Antecedents: {', '.join(max_lift_rule['antecedents'])}\")\n",
    "print(f\"Consequents: {', '.join(max_lift_rule['consequents'])}\")\n",
    "print(f\"Support: {max_lift_rule['support']:.4f}\")\n",
    "print(f\"Confidence: {max_lift_rule['confidence']:.4f}\")\n",
    "print(f\"Lift: {max_lift_rule['lift']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdef529-169a-453b-a74e-a6f96cfe3868",
   "metadata": {},
   "source": [
    "## Is the rule with the highest confidence the same as the rule with the highest lift? Why or why not?\n",
    "\n",
    "The **rule with the highest confidence** and the **rule with the highest lift** are **not the same** in this analysis, and here is why:\n",
    "\n",
    "---\n",
    "\n",
    "### Rule with highest confidence:\n",
    "- **Antecedents:** `JUMBO BAG WOODLAND ANIMALS`\n",
    "- **Consequents:** `POSTAGE`\n",
    "- **Support:** **0.0765** (7.65%)\n",
    "- **Confidence:** **1.00** (100%)\n",
    "- **Lift:** **1.31**\n",
    "\n",
    "This means that **every transaction** containing the *JUMBO BAG WOODLAND ANIMALS* also includes *POSTAGE*. The confidence of **1.00** indicates a perfect conditional probability: whenever the bag is bought, postage is always present. However, the lift is only **1.31**, showing that the presence of *POSTAGE* is only moderately more likely than by random chance in these transactions. This happens because *POSTAGE* is a very common item, appearing in many transactions overall, which reduces the relative strength of association.\n",
    "\n",
    "---\n",
    "\n",
    "### Rule with highest lift:\n",
    "- **Antecedents:** `PACK OF 6 SKULL PAPER CUPS`\n",
    "- **Consequents:** `PACK OF 6 SKULL PAPER PLATES`\n",
    "- **Support:** **0.0510** (5.1%)\n",
    "- **Confidence:** **0.80** (80%)\n",
    "- **Lift:** **14.25**\n",
    "\n",
    "This rule shows a very strong association between these two items. The confidence of **0.80** means that 80% of transactions containing the *PACK OF 6 SKULL PAPER CUPS* also contain the *PACK OF 6 SKULL PAPER PLATES*. The **lift of 14.25** indicates that these two items are bought together **over 14 times more frequently than if they were independent**, representing a very strong and meaningful relationship.\n",
    "\n",
    "---\n",
    "\n",
    "### Why are these rules different?\n",
    "\n",
    "- **Confidence** measures the likelihood of the consequent given the antecedent, which can be very high when the consequent item (*POSTAGE*) is very common overall. This explains the perfect confidence in the first rule but with a modest lift.\n",
    "  \n",
    "- **Lift** measures how much more frequently the antecedent and consequent occur together than expected if they were independent. A high lift value (like 14.25) indicates a statistically significant and strong association, even if confidence is lower.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- The **highest confidence rule** shows a very predictable but less interesting association, largely because *POSTAGE* appears frequently in many transactions.\n",
    "- The **highest lift rule** reveals a stronger, more surprising relationship between two less common items that are frequently purchased together.\n",
    "\n",
    "Therefore, **the rule with the highest confidence is not the same as the rule with the highest lift**, as they capture different dimensions of association strength in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## Citations:\n",
    "- https://www.kaggle.com/code/sefercanapaydn/apriori-algorithm-on-a-online-retail-store\n",
    "- https://www.kaggle.com/code/xvivancos/market-basket-analysis/report#data-analysis\n",
    "- https://www.kaggle.com/code/rockystats/apriori-algorithm-or-market-basket-analysis\n",
    "- https://www.kaggle.com/code/mbalvi75/15-apriori-arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731a3053-7954-4080-ace5-0bfc10aeeed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction Number  Chocolate Cake  Lemon Cake  Casino Cake  Opera Cake  \\\n",
      "0                   1               0           0            0           0   \n",
      "1                   2               0           0            0           0   \n",
      "2                   3               0           0            0           1   \n",
      "3                   4               0           0            0           0   \n",
      "4                   5               0           0            0           0   \n",
      "\n",
      "   Strawberry Cake  Truffle Cake  Chocolate Eclair  Coffee Eclair  \\\n",
      "0                0             0                 0              0   \n",
      "1                0             0                 0              1   \n",
      "2                0             0                 0              0   \n",
      "3                0             1                 0              0   \n",
      "4                0             0                 1              0   \n",
      "\n",
      "   Vanilla Eclair  ...  Lemon Lemonade  Raspberry Lemonade  Orange Juice  \\\n",
      "0               0  ...               0                   0             0   \n",
      "1               0  ...               0                   0             0   \n",
      "2               0  ...               0                   0             1   \n",
      "3               0  ...               0                   0             0   \n",
      "4               0  ...               0                   0             1   \n",
      "\n",
      "   Green Tea  Bottled Water  Hot Coffee  Chocolate Coffee  \\\n",
      "0          0              0           0                 0   \n",
      "1          0              0           1                 0   \n",
      "2          0              0           0                 0   \n",
      "3          0              0           0                 0   \n",
      "4          0              0           0                 0   \n",
      "\n",
      "   Vanilla Frappuccino  Cherry Soda  Single Espresso  \n",
      "0                    0            0                0  \n",
      "1                    0            0                0  \n",
      "2                    0            0                0  \n",
      "3                    1            0                0  \n",
      "4                    0            0                0  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 51 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   Transaction Number   75000 non-null  int64\n",
      " 1   Chocolate Cake       75000 non-null  int64\n",
      " 2   Lemon Cake           75000 non-null  int64\n",
      " 3   Casino Cake          75000 non-null  int64\n",
      " 4   Opera Cake           75000 non-null  int64\n",
      " 5   Strawberry Cake      75000 non-null  int64\n",
      " 6   Truffle Cake         75000 non-null  int64\n",
      " 7   Chocolate Eclair     75000 non-null  int64\n",
      " 8   Coffee Eclair        75000 non-null  int64\n",
      " 9   Vanilla Eclair       75000 non-null  int64\n",
      " 10  Napoleon Cake        75000 non-null  int64\n",
      " 11  Almond Tart          75000 non-null  int64\n",
      " 12  Apple Pie            75000 non-null  int64\n",
      " 13  Apple Tart           75000 non-null  int64\n",
      " 14  Apricot Tart         75000 non-null  int64\n",
      " 15  Berry Tart           75000 non-null  int64\n",
      " 16  Blackberry Tart      75000 non-null  int64\n",
      " 17  Blueberry Tart       75000 non-null  int64\n",
      " 18  Chocolate Tart       75000 non-null  int64\n",
      " 19  Cherry Tart          75000 non-null  int64\n",
      " 20  Lemon Tart           75000 non-null  int64\n",
      " 21  Pecan Tart           75000 non-null  int64\n",
      " 22  Ganache Cookie       75000 non-null  int64\n",
      " 23  Gongolais Cookie     75000 non-null  int64\n",
      " 24  Raspberry Cookie     75000 non-null  int64\n",
      " 25  Lemon Cookie         75000 non-null  int64\n",
      " 26  Chocolate Meringue   75000 non-null  int64\n",
      " 27  Vanilla Meringue     75000 non-null  int64\n",
      " 28  Marzipan Cookie      75000 non-null  int64\n",
      " 29  Tuile Cookie         75000 non-null  int64\n",
      " 30  Walnut Cookie        75000 non-null  int64\n",
      " 31  Almond Croissant     75000 non-null  int64\n",
      " 32  Apple Croissant      75000 non-null  int64\n",
      " 33  Apricot Croissant    75000 non-null  int64\n",
      " 34  Cheese Croissant     75000 non-null  int64\n",
      " 35  Chocolate Croissant  75000 non-null  int64\n",
      " 36  Apricot Danish       75000 non-null  int64\n",
      " 37  Apple Danish         75000 non-null  int64\n",
      " 38  Almond Twist         75000 non-null  int64\n",
      " 39  Almond Bear          75000 non-null  int64\n",
      " 40  Blueberry Danish     75000 non-null  int64\n",
      " 41  Lemon Lemonade       75000 non-null  int64\n",
      " 42  Raspberry Lemonade   75000 non-null  int64\n",
      " 43  Orange Juice         75000 non-null  int64\n",
      " 44  Green Tea            75000 non-null  int64\n",
      " 45  Bottled Water        75000 non-null  int64\n",
      " 46  Hot Coffee           75000 non-null  int64\n",
      " 47  Chocolate Coffee     75000 non-null  int64\n",
      " 48  Vanilla Frappuccino  75000 non-null  int64\n",
      " 49  Cherry Soda          75000 non-null  int64\n",
      " 50  Single Espresso      75000 non-null  int64\n",
      "dtypes: int64(51)\n",
      "memory usage: 29.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Problem 2\n",
    "# Step 1: Load Extended Bakery Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Extended Bakery dataset \n",
    "df = pd.read_csv('75000-out2-binary.csv')\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84c5ac11-4844-40e6-a259-3fb94637a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract the two item columns of interest: 'Chocolate Coffee' and 'Chocolate Cake'\n",
    "choco_coffee = df['Chocolate Coffee']\n",
    "choco_cake = df['Chocolate Cake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91bf05d3-874b-4c0b-b850-cefbcaffa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate the components of the contingency table (2x2 table)\n",
    "# Count of transactions where both items are present (1,1)\n",
    "n11 = np.sum((choco_coffee == 1) & (choco_cake == 1))\n",
    "\n",
    "# Count where Chocolate Coffee = 1, Chocolate Cake = 0\n",
    "n10 = np.sum((choco_coffee == 1) & (choco_cake == 0))\n",
    "\n",
    "# Count where Chocolate Coffee = 0, Chocolate Cake = 1\n",
    "n01 = np.sum((choco_coffee == 0) & (choco_cake == 1))\n",
    "\n",
    "# Count where both items are absent (0,0)\n",
    "n00 = np.sum((choco_coffee == 0) & (choco_cake == 0))\n",
    "\n",
    "# Total number of transactions\n",
    "N = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "801ea3a5-573e-47b7-b185-c3b58059861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Calculate the binary correlation coefficient Φ (phi coefficient)\n",
    "# Formula:\n",
    "# Φ = (n11 * n00 - n10 * n01) / sqrt( (n1dot * n0dot * ndot1 * ndot0) )\n",
    "# where\n",
    "# n1dot = n11 + n10 (row sum for Chocolate Coffee=1)\n",
    "# n0dot = n01 + n00 (row sum for Chocolate Coffee=0)\n",
    "# ndot1 = n11 + n01 (column sum for Chocolate Cake=1)\n",
    "# ndot0 = n10 + n00 (column sum for Chocolate Cake=0)\n",
    "\n",
    "n1dot = n11 + n10\n",
    "n0dot = n01 + n00\n",
    "ndot1 = n11 + n01\n",
    "ndot0 = n10 + n00\n",
    "\n",
    "numerator = (n11 * n00) - (n10 * n01)\n",
    "denominator = np.sqrt(n1dot * n0dot * ndot1 * ndot0)\n",
    "\n",
    "phi = numerator / denominator if denominator != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbab2b2f-906e-4eb8-a5d8-7ee35707de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contingency Table:\n",
      "                     Chocolate Cake=1 Chocolate Cake=0\n",
      "Chocolate Coffee=1   3303            2933           \n",
      "Chocolate Coffee=0   2962            65802          \n",
      "Total transactions: 75000\n",
      "\n",
      "Phi coefficient (Φ) between Chocolate Coffee and Chocolate Cake: 0.4856\n",
      "\n",
      "Symmetry check:\n",
      "The binary correlation coefficient Φ is symmetric by definition.\n",
      "Therefore, Φ({Chocolate Coffee} ⇒ {Chocolate Cake}) = Φ({Chocolate Cake} ⇒ {Chocolate Coffee}).\n",
      "This is because the formula and contingency table counts are invariant to swapping the variables.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Display contingency table clearly\n",
    "print(\"\\nContingency Table:\")\n",
    "print(f\"{'':<20} {'Chocolate Cake=1':<15} {'Chocolate Cake=0':<15}\")\n",
    "print(f\"{'Chocolate Coffee=1':<20} {n11:<15} {n10:<15}\")\n",
    "print(f\"{'Chocolate Coffee=0':<20} {n01:<15} {n00:<15}\")\n",
    "print(f\"Total transactions: {N}\")\n",
    "\n",
    "print(f\"\\nPhi coefficient (Φ) between Chocolate Coffee and Chocolate Cake: {phi:.4f}\")\n",
    "\n",
    "# Step 9: Explain symmetry of Φ coefficient\n",
    "print(\"\\nSymmetry check:\")\n",
    "print(\"The binary correlation coefficient Φ is symmetric by definition.\")\n",
    "print(\"Therefore, Φ({Chocolate Coffee} ⇒ {Chocolate Cake}) = Φ({Chocolate Cake} ⇒ {Chocolate Coffee}).\")\n",
    "print(\"This is because the formula and contingency table counts are invariant to swapping the variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9aec1-9260-4786-9817-ec1a90b34feb",
   "metadata": {},
   "source": [
    "## 1) Are these two items symmetric binary variables? Provide supporting calculations.\n",
    "\n",
    "To evaluate whether **Chocolate Coffee** and **Chocolate Cake** can be considered **symmetric binary variables**, we first compute the **binary correlation coefficient (Phi)**. This coefficient measures the strength and direction of the association between two binary variables, with values ranging from -1 (perfect negative association) to +1 (perfect positive association), and 0 indicating no association.\n",
    "\n",
    "---\n",
    "\n",
    "### Contingency Table Overview\n",
    "\n",
    "The observed counts from the transaction data are summarized in the contingency table below:\n",
    "\n",
    "|                            | **Chocolate Cake = 1** | **Chocolate Cake = 0** |\n",
    "|----------------------------|------------------------|------------------------|\n",
    "| **Chocolate Coffee = 1**   | 3303                   | 2933                   |\n",
    "| **Chocolate Coffee = 0**   | 2962                   | 65802                  |\n",
    "\n",
    "These counts represent the frequency of co-occurrence and individual occurrences of the two items:\n",
    "\n",
    "- n11 = 3303 — both items purchased together  \n",
    "- n10 = 2933 — only Chocolate Coffee purchased  \n",
    "- n01 = 2962 — only Chocolate Cake purchased  \n",
    "- n00 = 65802 — neither item purchased  \n",
    "\n",
    "---\n",
    "\n",
    "### Calculation of Phi Coefficient (Phi)\n",
    "\n",
    "The Phi coefficient is defined as:\n",
    "\n",
    "**Phi = (n11 × n00 - n10 × n01) / sqrt(n1• × n0• × n•1 × n•0)**\n",
    "\n",
    "where the marginal totals are:\n",
    "\n",
    "- n1• = n11 + n10 = 3303 + 2933 = 6236  \n",
    "- n0• = n01 + n00 = 2962 + 65802 = 68764  \n",
    "- n•1 = n11 + n01 = 3303 + 2962 = 6265  \n",
    "- n•0 = n10 + n00 = 2933 + 65802 = 68735  \n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "Phi = (3303 × 65802 - 2933 × 2962) / sqrt(6236 × 68764 × 6265 × 68735)  \n",
    "= (217,411,506 - 8,686,846) / sqrt(1.2412 × 10¹⁶)  \n",
    "= 208,724,660 / 429,756,218.5  \n",
    "≈ 0.4856\n",
    "\n",
    "This indicates a **moderate positive correlation** between the purchase of Chocolate Coffee and Chocolate Cake. Such a relationship suggests that when a customer buys one of these items, there is an increased likelihood of also purchasing the other compared to chance.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Would the association rules {Chocolate Coffee} ⇒ {Chocolate Cake} have the same value for Phi as {Chocolate Cake} ⇒ {Chocolate Coffee}?\n",
    "\n",
    "By the mathematical properties of the Phi coefficient, it is a **symmetric measure** of association between two binary variables. The formula depends solely on the contingency table counts, which remain unchanged when swapping the antecedent and consequent.\n",
    "\n",
    "Consequently,\n",
    "\n",
    "**Phi({Chocolate Coffee} ⇒ {Chocolate Cake}) = Phi({Chocolate Cake} ⇒ {Chocolate Coffee}) = 0.4856**\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "\n",
    "- While **confidence** and **lift** for these two association rules may differ, reflecting the directional nature of conditional probabilities, the **Phi coefficient remains identical regardless of rule direction**.  \n",
    "- This symmetry makes Phi an effective metric for assessing the **intrinsic strength of co-occurrence** without bias toward causality or directionality.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- The computed Phi coefficient of approximately **0.4856** demonstrates a **moderate positive correlation** between Chocolate Coffee and Chocolate Cake.  \n",
    "- The **symmetry of Phi confirms** that these two items are **symmetric binary variables**.  \n",
    "- Consequently, the value of Phi is **identical for both association rules**:  \n",
    "  Phi({Chocolate Coffee} ⇒ {Chocolate Cake}) = Phi({Chocolate Cake} ⇒ {Chocolate Coffee})  \n",
    "  highlighting the bidirectional nature of their association.\n",
    "\n",
    "---\n",
    "\n",
    "#### Citations:\n",
    "\n",
    "- https://www.youtube.com/watch?v=SVM_pX0oTU8  \n",
    "- https://www.youtube.com/watch?v=4QIWJVVWJdQ  \n",
    "- https://www.kaggle.com/code/busegngr/recommendation-system  \n",
    "- https://www.kaggle.com/code/mgmarques/customer-segmentation-and-market-basket-analysis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c484359-6c17-4f41-8c3d-1a505ff4d40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
